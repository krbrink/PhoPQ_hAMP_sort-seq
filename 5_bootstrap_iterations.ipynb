{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from common_dirs_fns import *\n",
    "from sort_seq_functions import *\n",
    "import pandas as pd\n",
    "\n",
    "# For progress bars\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import peptide count and frequency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import peptide count and frequency data\n",
    "tln_count_df = pd.read_csv(analysis_path+'tln_count_df.csv',\n",
    "                                                    index_col=[0,1],\n",
    "                                                    header=[0,1],\n",
    "                                                    na_filter=False)\n",
    "\n",
    "# Import the processed count and frequency data from sort-seq notebook\n",
    "tln_count_df_processed = rename_unnamed(pd.read_csv(analysis_path+'tln_count_df_processed.csv',\n",
    "                                                    index_col=[0],\n",
    "                                                    header=[0,1],\n",
    "                                                    na_filter=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths for storing bootstrap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_path = analysis_path+'bootstrapping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite existing bootstrap input and output directories\n",
    "# Uncomment when conducting iterations for the first time\n",
    "# or if repeating the analysis\n",
    "\n",
    "# for subfolder in ['input','output']:\n",
    "#     rewrite_directory(bootstrap_path+subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 1000 simulated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes approximately 4 hours to run\n",
    "\n",
    "# Generate simulated datasets by drawing with replacement from\n",
    "# underlying count data (tln_count_df)\n",
    "for i in tqdm(range(n_iter)):\n",
    "    random_bins = make_random_bins(tln_count_df, mixed_stats_bins)\n",
    "    random_bins.to_csv(bootstrap_path+'input/'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use simple fitting function to estimate distribution parameters for each peptide in each simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes over 16 hours to run\n",
    "# Different iterations will have different numbers of peptides, since not all low-count peptides\n",
    "# will have 10 reads in each iteration due to random sampling\n",
    "minimum_reads = 10\n",
    "\n",
    "for i in tqdm(range(n_iter)):\n",
    "    # Read in input file (simulated dataset) for each iteration\n",
    "    random_df = pd.read_csv(bootstrap_path+'input/'+str(i)+'.csv',\n",
    "                            index_col=[0,1], header=[0,1], na_filter=False)\n",
    "    \n",
    "    # Process the dataframe\n",
    "    random_df_processed = process_tln_count_df(random_df)\n",
    "    \n",
    "    # Generate stats_table for all peptides with > minimum reads using simple fitting\n",
    "    stats_table = make_stats_table(random_df_processed[random_df_processed['TotalReads']>minimum_reads],\n",
    "                              bootstrap_path+'output/'+'stats_table_'+str(i)+'.csv',\n",
    "                              upper, lower, 'Simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new table that contains fits from each bootstrap iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e45af226dc4c6a9aba04a265f98016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This takes about 15 minutes to run\n",
    "\n",
    "for i in tqdm(range(n_iter)):\n",
    "    # Read in output table\n",
    "    random_stats_table = pd.read_csv(bootstrap_path+'output/'+'stats_table_'+str(i)+'.csv',\n",
    "                            index_col=[0], header=[0], na_filter=False)\n",
    "    \n",
    "    # Transform the table's columns to a multiindex to keep track of the iteration number\n",
    "    random_stats_table.columns = pd.MultiIndex.from_product([[str(i)],random_stats_table.columns])\n",
    "    \n",
    "    try:\n",
    "        # If bootstrap_stats_table already exists, join this iteration's stats_table\n",
    "        # to the previous iterations'\n",
    "        bootstrap_stats_table = bootstrap_stats_table.join(random_stats_table,how='outer')\n",
    "    \n",
    "    except NameError:\n",
    "        # If bootstrap_stats_table doesn't exist (i=0), create this variable to keep\n",
    "        # track of information for all iterations\n",
    "        bootstrap_stats_table = random_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bootstrap information to csv\n",
    "bootstrap_stats_table.to_csv(analysis_path+'stats_table_bootstraps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table to summarize bootstrap results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09720f548e824985a48963df7bdfb3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV\n",
      "Fold Change\n",
      "Mean\n",
      "Mu\n",
      "Sigma\n",
      "StdDev\n",
      "Variance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate median, 5th percentile, and 95th percentile information for all\n",
    "# peptide distribution statistics across bootstrap iterations to get approximate\n",
    "# error bounds on those variables\n",
    "\n",
    "summary_table = pd.DataFrame(index=bootstrap_stats_table.index,\n",
    "                            columns=pd.MultiIndex.from_product([\n",
    "                                        bootstrap_stats_table.columns.levels[1],\n",
    "                                        ['Median','Pct5','Pct95']]))\n",
    "\n",
    "for metric in tqdm(summary_table.columns.levels[0]):\n",
    "    print(metric)\n",
    "    summary_table[(metric,'Median')] = bootstrap_stats_table.xs(metric, level=1, axis=1).median(axis=1)\n",
    "    summary_table[(metric,'Pct5')] = bootstrap_stats_table.xs(metric, level=1, axis=1).quantile(0.05, axis=1)\n",
    "    summary_table[(metric,'Pct95')] = bootstrap_stats_table.xs(metric, level=1, axis=1).quantile(0.95, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of iterations where there were sufficient simulated reads (> 10)\n",
    "# to calculate distribution statistics\n",
    "summary_table['N_Iter'] = bootstrap_stats_table.xs('Mean', level=1, axis=1).count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to csv\n",
    "summary_table.to_csv(analysis_path+'bootstrap_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
